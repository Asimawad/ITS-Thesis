\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}
Recent findings suggest that reasoning strategies applied during inference can yield more significant performance gains in large language models (LLMs) than merely increasing their parameter scale. Furthermore, the emergence of advanced open-source LLMs, such as those distilled from DeepSeek-R1—which matches the performance of its closed-source counterpart, OpenAI-o1, offers new opportunities for exploration. Leveraging these more capable LLMs, we aim to evaluate their performance on complex tasks in machine learning engineering.

To this end, MLE-Bench provides an ideal benchmark. Designed to assess the machine learning engineering capabilities of AI agents, MLE-Bench comprises 75 diverse Kaggle competitions. Its primary goal is to comprehensively evaluate AI agents' ability to design and implement end-to-end machine learning pipelines, making it a rigorous testbed for these advanced LLMs.

This project examines the effectiveness of these distilled open-source LLMs when paired with inference-time reasoning strategies within and Agentic framework, on the machine learning tasks presented by MLE-Bench. The primary objective is to compare the performance of these open-source models with the more established LLM-based approaches outlined in the MLE-Bench paper. Ultimately, this work supports the broader vision of integrating LLM-based agentic systems into AI research workflows.

% \begin{otherlanguage}{arabic}
%     هذا هو الملخص العربي لمشروع البحث الخاص بك.
% \end{otherlanguage}
\vfill

\section*{Declaration}

I, the undersigned, hereby declare that the work contained in this research project is my original work, and that any work done by others or by myself previously has been acknowledged and referenced accordingly.
% \includegraphics[height=2cm]{images/signature.png} \newline \hrule

Asim Osman, 12 June 2025